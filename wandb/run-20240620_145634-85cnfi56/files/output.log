/home/areka/pdan_da/apmeter.py:27: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  self.scores = torch.FloatTensor(torch.FloatStorage())
Traceback (most recent call last):
  File "/home/areka/pdan_da/train_PDAN.py", line 374, in <module>
    run([(rgb_model, 0, dataloaders, optimizer, lr_sched, args.comp_info)], criterion, num_epochs=int(args.epoch))
  File "/home/areka/pdan_da/train_PDAN.py", line 146, in run
    train_map, train_loss = train_step(model, gpu, optimizer, dataloader['train'], epoch)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/pdan_da/train_PDAN.py", line 220, in train_step
    outputs, loss, probs, err = run_network(model, data, gpu, epoch)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/pdan_da/train_PDAN.py", line 192, in run_network
    activation = model(inputs, mask_new)
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/pdan_da/PDAN.py", line 43, in forward
    self.summary = self.summarization_module(r_x)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/pdan_da/PDAN.py", line 24, in forward
    attn_output, _ = self.attn(query=tokens, key=inputs, value=inputs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 1266, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/areka/miniconda3/envs/pdan_a/lib/python3.12/site-packages/torch/nn/functional.py", line 5410, in multi_head_attention_forward
    k = k.view(k.shape[0], bsz * num_heads, head_dim).transpose(0, 1)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[32, 128, 128]' is invalid for input of size 2211840
Epoch 0/99
----------